name: CI/CD - Credit Card Fraud ML

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      # 1Ô∏è‚É£ Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Authenticate to GCP
      - name: Set up GCP credentials
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # 3Ô∏è‚É£ Configure Docker for Artifact Registry
      - name: Configure Docker
        run: gcloud auth configure-docker us-central1-docker.pkg.dev

      # 4Ô∏è‚É£ Deploy MLflow server to GKE
      - name: Deploy MLflow to GKE
        run: |
          kubectl apply -f mlflow-deployment.yaml
          kubectl apply -f mlflow-service.yaml

      # 5Ô∏è‚É£ Wait for MLflow external IP
      - name: Wait for MLflow external IP
        id: mlflow_ip
        run: |
          echo "Waiting for MLflow external IP..."
          MLFLOW_IP=""
          while [ -z "$MLFLOW_IP" ]; do
            sleep 5
            MLFLOW_IP=$(kubectl get svc mlflow-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          done
          echo "MLflow IP: $MLFLOW_IP"
          echo "MLFLOW_IP=$MLFLOW_IP" >> $GITHUB_ENV

      # 6Ô∏è‚É£ Run MLflow logger
      - name: Run MLflow logger
        run: |
          python mlflow_logger.py --mlflow_ip ${{ env.MLFLOW_IP }}:5000

      # 7Ô∏è‚É£ Build Docker image for ML model
      - name: Build Docker image
        run: |
          IMAGE="us-central1-docker.pkg.dev/durable-unity-468703-a2/my-repo/demo_log:${GITHUB_SHA}"
          docker build --build-arg MODEL_FILE=model_clean.joblib -t $IMAGE .
          echo "IMAGE=$IMAGE" >> $GITHUB_ENV

      # 8Ô∏è‚É£ Push Docker image
      - name: Push Docker image
        run: docker push $IMAGE

      # 9Ô∏è‚É£ Get GKE credentials for model service
      - name: Get GKE credentials
        uses: google-github-actions/get-gke-credentials@v1
        with:
          cluster_name: demo-log-ml-cluster-1
          location: us-central1-a
          project_id: durable-unity-468703-a2

      # üîü Deploy model service manifests
      - name: Deploy model service to GKE
        run: |
          sed -i "s|image: .*|image: $IMAGE|" deployment.yaml
          kubectl apply -f deployment.yaml
          kubectl apply -f service.yaml
          kubectl apply -f hpa.yaml

      # 1Ô∏è‚É£1Ô∏è‚É£ Wait for external IP of model service
      - name: Wait for model service external IP
        id: get_ip
        run: |
          echo "Waiting for external IP..."
          SERVICE_IP=""
          while [ -z "$SERVICE_IP" ]; do
            sleep 5
            SERVICE_IP=$(kubectl get svc demo-log-ml-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          done
          echo "External IP: $SERVICE_IP"
          echo "SERVICE_IP=$SERVICE_IP" >> $GITHUB_ENV

      # 1Ô∏è‚É£2Ô∏è‚É£ Install wrk
      - name: Install wrk
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk

      # 1Ô∏è‚É£3Ô∏è‚É£ Run wrk load test
      - name: Run wrk load test
        run: |
          echo "Running wrk against http://${{ env.SERVICE_IP }}"
          wrk -t2 -c10 -d30s -s post.lua http://${{ env.SERVICE_IP }}/predict > wrk_output.txt

      # 1Ô∏è‚É£4Ô∏è‚É£ Upload wrk output as artifact
      - name: Upload wrk output
        uses: actions/upload-artifact@v4
        with:
          name: wrk-load-test
          path: wrk_output.txt
